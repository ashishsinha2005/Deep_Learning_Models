{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebd0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python detect_mask_video.py\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa56e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to capture the image \n",
    "def detect_and_predict_mask(frame,faceNet,maskNet):\n",
    "    # to get the dimension of the frame and to construct the blob\n",
    "    (h,w)= frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame,1.0,(300,300),\n",
    "                                 (104.0,177.0,123.0))\n",
    "    \n",
    "    #pass the blob through model and detect the face using faceNet\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "    \n",
    "    #initialize the list of face and the corresponding locatins and the list of predicitons from our face mask model\n",
    "    \n",
    "    faces =[]\n",
    "    locs =[]\n",
    "    preds =[]\n",
    "    \n",
    "    # loop over detections\n",
    "    for i in range(0,detections.shape[2]):\n",
    "        # extract the probability\n",
    "        confidence = detections[0,0,i,2]\n",
    "        \n",
    "        #filter out weak detections by ensuring the confidence/probability value\n",
    "        # (i.e) the confidence value is greater than the min conf value\n",
    "        \n",
    "        if confidence>args['confidence']:\n",
    "            #compute the x and y coordinates of bounding box \n",
    "            \n",
    "            box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "            (startX,startY,endX,endY)=box.astype(\"int\")\n",
    "            \n",
    "            #ensure the box falls within the face dim\n",
    "            (startX,startY) =(max(0,startX),max(0,startY))\n",
    "            (endX,endY) = (min(w-1,endX),min(h-1,endY))\n",
    "            face = frame[startY:endY,startX:endX]\n",
    "\n",
    "            # Debugging statements\n",
    "            print(f\"Detection {i}: confidence={confidence}\")\n",
    "            print(f\"Bounding box: startX={startX}, startY={startY}, endX={endX}, endY={endY}\")\n",
    "            print(f\"Face shape: {face.shape}\")\n",
    "\n",
    "            if face.size == 0:\n",
    "                print(\"Empty face image detected, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            #extract the face ROI, convert it to BGR to RGB channel ordering, resize it to 224x224, and preprocess it\n",
    "            # face = frame[startY:endY,startX:endX]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face,(224,224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "            \n",
    "            # add the face and bounding box to the respective list\n",
    "            faces.append(face)\n",
    "            locs.append((startX,startY,endX,endY))\n",
    "            \n",
    "    # to give a condition to predict atleast one face was detected\n",
    "    if len(faces)>0:\n",
    "# for faster inference we'll make batch predictions on *all*\n",
    "# faces at the same time rather than one-by-one predictions\n",
    "# in the above `for` loop\n",
    "        faces = np.array(faces,dtype ='float32')\n",
    "        preds = maskNet.predict(faces,batch_size = 32)\n",
    "        \n",
    "    return (locs,preds)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b513c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototxt path: C:\\HOPE\\Deep Learning\\Face Mask Dectection\\face_detector\\deploy.prototxt\n",
      "Weights path: C:\\HOPE\\Deep Learning\\Face Mask Dectection\\face_detector\\res10_300x300_ssd_iter_140000.caffemodel\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "# Construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-f\", \"--face\", type=str, default=\"face_detector\", help=\"path to face detector model directory\")\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, default=\"mask_detector.h5\", help=\"path to trained face mask detector model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5, help=\"minimum probability to filter weak detections\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# Construct the absolute paths to the model files\n",
    "project_root = os.path.abspath(os.path.dirname(r\"C:\\HOPE\\Deep Learning\\Face Mask Dectection\\face_detector\"))\n",
    "face_detector_directory = os.path.join(project_root, 'face_detector')\n",
    "prototxtPath = os.path.join(face_detector_directory, \"deploy.prototxt\")\n",
    "weightsPath = os.path.join(face_detector_directory, \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "print(f\"Prototxt path: {prototxtPath}\")\n",
    "print(f\"Weights path: {weightsPath}\")\n",
    "\n",
    "if not os.path.exists(prototxtPath):\n",
    "    print(f\"Error: {prototxtPath} not found.\")\n",
    "if not os.path.exists(weightsPath):\n",
    "    print(f\"Error: {weightsPath} not found.\")\n",
    "\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df553c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the face mask detector model from disk\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "maskNet = load_model(args[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e97d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a644e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 0: confidence=0.9850894212722778\n",
      "Bounding box: startX=192, startY=121, endX=268, endY=223\n",
      "Face shape: (102, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9852746725082397\n",
      "Bounding box: startX=193, startY=121, endX=267, endY=225\n",
      "Face shape: (104, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Detection 0: confidence=0.9902476668357849\n",
      "Bounding box: startX=193, startY=121, endX=266, endY=224\n",
      "Face shape: (103, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9899994730949402\n",
      "Bounding box: startX=193, startY=121, endX=266, endY=224\n",
      "Face shape: (103, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9855647683143616\n",
      "Bounding box: startX=193, startY=121, endX=266, endY=224\n",
      "Face shape: (103, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9920416474342346\n",
      "Bounding box: startX=191, startY=121, endX=266, endY=222\n",
      "Face shape: (101, 75, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Detection 0: confidence=0.9414042830467224\n",
      "Bounding box: startX=188, startY=115, endX=267, endY=212\n",
      "Face shape: (97, 79, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.9391964673995972\n",
      "Bounding box: startX=177, startY=88, endX=267, endY=193\n",
      "Face shape: (105, 90, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9628816843032837\n",
      "Bounding box: startX=172, startY=62, endX=268, endY=186\n",
      "Face shape: (124, 96, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9153382182121277\n",
      "Bounding box: startX=167, startY=39, endX=267, endY=179\n",
      "Face shape: (140, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Detection 0: confidence=0.5725461840629578\n",
      "Bounding box: startX=160, startY=25, endX=274, endY=156\n",
      "Face shape: (131, 114, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.6427282094955444\n",
      "Bounding box: startX=147, startY=33, endX=272, endY=163\n",
      "Face shape: (130, 125, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.7642271518707275\n",
      "Bounding box: startX=149, startY=36, endX=272, endY=171\n",
      "Face shape: (135, 123, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.7427883744239807\n",
      "Bounding box: startX=145, startY=36, endX=271, endY=169\n",
      "Face shape: (133, 126, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.6706950068473816\n",
      "Bounding box: startX=149, startY=41, endX=271, endY=168\n",
      "Face shape: (127, 122, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.577552318572998\n",
      "Bounding box: startX=151, startY=39, endX=275, endY=183\n",
      "Face shape: (144, 124, 3)\n",
      "Detection 1: confidence=0.5260699391365051\n",
      "Bounding box: startX=274, startY=213, endX=340, endY=287\n",
      "Face shape: (74, 66, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.5706465244293213\n",
      "Bounding box: startX=160, startY=43, endX=271, endY=180\n",
      "Face shape: (137, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.545735776424408\n",
      "Bounding box: startX=156, startY=53, endX=271, endY=178\n",
      "Face shape: (125, 115, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.6065847873687744\n",
      "Bounding box: startX=160, startY=56, endX=267, endY=182\n",
      "Face shape: (126, 107, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.7564902305603027\n",
      "Bounding box: startX=171, startY=57, endX=273, endY=184\n",
      "Face shape: (127, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.8752989768981934\n",
      "Bounding box: startX=171, startY=55, endX=273, endY=191\n",
      "Face shape: (136, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9901240468025208\n",
      "Bounding box: startX=172, startY=47, endX=273, endY=185\n",
      "Face shape: (138, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9871410131454468\n",
      "Bounding box: startX=172, startY=45, endX=274, endY=180\n",
      "Face shape: (135, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9862150549888611\n",
      "Bounding box: startX=172, startY=44, endX=275, endY=178\n",
      "Face shape: (134, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9609897136688232\n",
      "Bounding box: startX=171, startY=45, endX=272, endY=178\n",
      "Face shape: (133, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9794548749923706\n",
      "Bounding box: startX=172, startY=44, endX=273, endY=176\n",
      "Face shape: (132, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Detection 0: confidence=0.9956633448600769\n",
      "Bounding box: startX=174, startY=44, endX=277, endY=178\n",
      "Face shape: (134, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9913457632064819\n",
      "Bounding box: startX=174, startY=43, endX=279, endY=177\n",
      "Face shape: (134, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9866402745246887\n",
      "Bounding box: startX=174, startY=43, endX=278, endY=177\n",
      "Face shape: (134, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9937618374824524\n",
      "Bounding box: startX=176, startY=44, endX=279, endY=176\n",
      "Face shape: (132, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9863226413726807\n",
      "Bounding box: startX=175, startY=43, endX=278, endY=177\n",
      "Face shape: (134, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9924291968345642\n",
      "Bounding box: startX=174, startY=44, endX=279, endY=177\n",
      "Face shape: (133, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9978728294372559\n",
      "Bounding box: startX=174, startY=45, endX=277, endY=176\n",
      "Face shape: (131, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9982779026031494\n",
      "Bounding box: startX=175, startY=44, endX=278, endY=177\n",
      "Face shape: (133, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9954814910888672\n",
      "Bounding box: startX=175, startY=43, endX=279, endY=178\n",
      "Face shape: (135, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Detection 0: confidence=0.9992635846138\n",
      "Bounding box: startX=172, startY=43, endX=280, endY=178\n",
      "Face shape: (135, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9696124792098999\n",
      "Bounding box: startX=174, startY=45, endX=275, endY=180\n",
      "Face shape: (135, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9911618232727051\n",
      "Bounding box: startX=172, startY=46, endX=274, endY=178\n",
      "Face shape: (132, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9816686511039734\n",
      "Bounding box: startX=172, startY=45, endX=273, endY=180\n",
      "Face shape: (135, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.965710461139679\n",
      "Bounding box: startX=171, startY=46, endX=272, endY=181\n",
      "Face shape: (135, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9134865403175354\n",
      "Bounding box: startX=169, startY=49, endX=272, endY=182\n",
      "Face shape: (133, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.5553888082504272\n",
      "Bounding box: startX=165, startY=61, endX=283, endY=192\n",
      "Face shape: (131, 118, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9005066752433777\n",
      "Bounding box: startX=171, startY=62, endX=272, endY=191\n",
      "Face shape: (129, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9813620448112488\n",
      "Bounding box: startX=171, startY=53, endX=272, endY=194\n",
      "Face shape: (141, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Detection 0: confidence=0.9948467016220093\n",
      "Bounding box: startX=170, startY=41, endX=267, endY=185\n",
      "Face shape: (144, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9984214305877686\n",
      "Bounding box: startX=169, startY=37, endX=268, endY=176\n",
      "Face shape: (139, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9993295669555664\n",
      "Bounding box: startX=169, startY=40, endX=271, endY=179\n",
      "Face shape: (139, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9996894598007202\n",
      "Bounding box: startX=170, startY=43, endX=272, endY=184\n",
      "Face shape: (141, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9998502731323242\n",
      "Bounding box: startX=172, startY=42, endX=274, endY=180\n",
      "Face shape: (138, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9997902512550354\n",
      "Bounding box: startX=171, startY=43, endX=273, endY=180\n",
      "Face shape: (137, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9998568296432495\n",
      "Bounding box: startX=173, startY=44, endX=274, endY=180\n",
      "Face shape: (136, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Detection 0: confidence=0.999922513961792\n",
      "Bounding box: startX=174, startY=43, endX=276, endY=180\n",
      "Face shape: (137, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9998866319656372\n",
      "Bounding box: startX=174, startY=43, endX=275, endY=180\n",
      "Face shape: (137, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9997739195823669\n",
      "Bounding box: startX=174, startY=44, endX=274, endY=176\n",
      "Face shape: (132, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9996960163116455\n",
      "Bounding box: startX=172, startY=42, endX=272, endY=175\n",
      "Face shape: (133, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9997878670692444\n",
      "Bounding box: startX=174, startY=43, endX=274, endY=176\n",
      "Face shape: (133, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9999080896377563\n",
      "Bounding box: startX=174, startY=43, endX=275, endY=177\n",
      "Face shape: (134, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9998292922973633\n",
      "Bounding box: startX=172, startY=41, endX=273, endY=177\n",
      "Face shape: (136, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9996795654296875\n",
      "Bounding box: startX=169, startY=41, endX=272, endY=177\n",
      "Face shape: (136, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.999985933303833\n",
      "Bounding box: startX=177, startY=42, endX=279, endY=179\n",
      "Face shape: (137, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9999939203262329\n",
      "Bounding box: startX=185, startY=39, endX=285, endY=178\n",
      "Face shape: (139, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9999890327453613\n",
      "Bounding box: startX=188, startY=42, endX=287, endY=181\n",
      "Face shape: (139, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9999518394470215\n",
      "Bounding box: startX=189, startY=42, endX=288, endY=176\n",
      "Face shape: (134, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9999691247940063\n",
      "Bounding box: startX=186, startY=41, endX=285, endY=177\n",
      "Face shape: (136, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Detection 0: confidence=0.9999710321426392\n",
      "Bounding box: startX=178, startY=42, endX=279, endY=176\n",
      "Face shape: (134, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9999192953109741\n",
      "Bounding box: startX=176, startY=43, endX=276, endY=178\n",
      "Face shape: (135, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.999860405921936\n",
      "Bounding box: startX=175, startY=44, endX=274, endY=178\n",
      "Face shape: (134, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9998220801353455\n",
      "Bounding box: startX=176, startY=44, endX=275, endY=177\n",
      "Face shape: (133, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9998175501823425\n",
      "Bounding box: startX=176, startY=45, endX=273, endY=179\n",
      "Face shape: (134, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9998762607574463\n",
      "Bounding box: startX=176, startY=44, endX=275, endY=177\n",
      "Face shape: (133, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9998795986175537\n",
      "Bounding box: startX=176, startY=45, endX=275, endY=178\n",
      "Face shape: (133, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9998284578323364\n",
      "Bounding box: startX=176, startY=45, endX=274, endY=177\n",
      "Face shape: (132, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9998483657836914\n",
      "Bounding box: startX=175, startY=45, endX=275, endY=177\n",
      "Face shape: (132, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.999915599822998\n",
      "Bounding box: startX=177, startY=45, endX=276, endY=179\n",
      "Face shape: (134, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9998955726623535\n",
      "Bounding box: startX=177, startY=44, endX=274, endY=179\n",
      "Face shape: (135, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.9914011359214783\n",
      "Bounding box: startX=177, startY=48, endX=274, endY=179\n",
      "Face shape: (131, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.6123054623603821\n",
      "Bounding box: startX=179, startY=55, endX=277, endY=182\n",
      "Face shape: (127, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9608820676803589\n",
      "Bounding box: startX=177, startY=57, endX=280, endY=202\n",
      "Face shape: (145, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.8971664905548096\n",
      "Bounding box: startX=174, startY=58, endX=276, endY=200\n",
      "Face shape: (142, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Detection 0: confidence=0.9608646631240845\n",
      "Bounding box: startX=174, startY=59, endX=278, endY=191\n",
      "Face shape: (132, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9198977947235107\n",
      "Bounding box: startX=180, startY=58, endX=282, endY=191\n",
      "Face shape: (133, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9562681317329407\n",
      "Bounding box: startX=178, startY=63, endX=281, endY=190\n",
      "Face shape: (127, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Detection 0: confidence=0.9838142395019531\n",
      "Bounding box: startX=179, startY=63, endX=278, endY=193\n",
      "Face shape: (130, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9939551949501038\n",
      "Bounding box: startX=180, startY=62, endX=277, endY=196\n",
      "Face shape: (134, 97, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9869497418403625\n",
      "Bounding box: startX=179, startY=60, endX=276, endY=193\n",
      "Face shape: (133, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9521892070770264\n",
      "Bounding box: startX=179, startY=59, endX=276, endY=193\n",
      "Face shape: (134, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9438300728797913\n",
      "Bounding box: startX=178, startY=60, endX=274, endY=192\n",
      "Face shape: (132, 96, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9264489412307739\n",
      "Bounding box: startX=180, startY=59, endX=275, endY=190\n",
      "Face shape: (131, 95, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9165816307067871\n",
      "Bounding box: startX=179, startY=58, endX=274, endY=183\n",
      "Face shape: (125, 95, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Detection 0: confidence=0.8424860239028931\n",
      "Bounding box: startX=176, startY=58, endX=272, endY=184\n",
      "Face shape: (126, 96, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Detection 0: confidence=0.9297829866409302\n",
      "Bounding box: startX=176, startY=59, endX=270, endY=184\n",
      "Face shape: (125, 94, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Detection 0: confidence=0.9244953989982605\n",
      "Bounding box: startX=177, startY=57, endX=271, endY=186\n",
      "Face shape: (129, 94, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Detection 0: confidence=0.8198549747467041\n",
      "Bounding box: startX=175, startY=59, endX=269, endY=187\n",
      "Face shape: (128, 94, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.7914895415306091\n",
      "Bounding box: startX=175, startY=59, endX=269, endY=188\n",
      "Face shape: (129, 94, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.8643560409545898\n",
      "Bounding box: startX=176, startY=59, endX=269, endY=189\n",
      "Face shape: (130, 93, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Detection 0: confidence=0.8120535612106323\n",
      "Bounding box: startX=175, startY=59, endX=270, endY=191\n",
      "Face shape: (132, 95, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Detection 0: confidence=0.9065830111503601\n",
      "Bounding box: startX=176, startY=59, endX=269, endY=190\n",
      "Face shape: (131, 93, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Detection 0: confidence=0.7069595456123352\n",
      "Bounding box: startX=176, startY=58, endX=272, endY=190\n",
      "Face shape: (132, 96, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.7184252738952637\n",
      "Bounding box: startX=181, startY=75, endX=294, endY=212\n",
      "Face shape: (137, 113, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Detection 0: confidence=0.9951710104942322\n",
      "Bounding box: startX=184, startY=76, endX=283, endY=215\n",
      "Face shape: (139, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9858139157295227\n",
      "Bounding box: startX=182, startY=77, endX=273, endY=204\n",
      "Face shape: (127, 91, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9736029505729675\n",
      "Bounding box: startX=182, startY=75, endX=270, endY=198\n",
      "Face shape: (123, 88, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.9805969595909119\n",
      "Bounding box: startX=176, startY=74, endX=266, endY=190\n",
      "Face shape: (116, 90, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.9832373261451721\n",
      "Bounding box: startX=174, startY=77, endX=263, endY=194\n",
      "Face shape: (117, 89, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9317294359207153\n",
      "Bounding box: startX=174, startY=81, endX=262, endY=198\n",
      "Face shape: (117, 88, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9602059721946716\n",
      "Bounding box: startX=174, startY=87, endX=261, endY=205\n",
      "Face shape: (118, 87, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9746450185775757\n",
      "Bounding box: startX=175, startY=92, endX=263, endY=208\n",
      "Face shape: (116, 88, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9785041213035583\n",
      "Bounding box: startX=177, startY=96, endX=261, endY=207\n",
      "Face shape: (111, 84, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9499645829200745\n",
      "Bounding box: startX=178, startY=95, endX=262, endY=210\n",
      "Face shape: (115, 84, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9619196653366089\n",
      "Bounding box: startX=179, startY=98, endX=262, endY=209\n",
      "Face shape: (111, 83, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9514260292053223\n",
      "Bounding box: startX=178, startY=99, endX=263, endY=212\n",
      "Face shape: (113, 85, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.8998886346817017\n",
      "Bounding box: startX=180, startY=103, endX=262, endY=214\n",
      "Face shape: (111, 82, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.8877338171005249\n",
      "Bounding box: startX=181, startY=106, endX=264, endY=215\n",
      "Face shape: (109, 83, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.8824481964111328\n",
      "Bounding box: startX=182, startY=108, endX=264, endY=215\n",
      "Face shape: (107, 82, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Detection 0: confidence=0.9347255825996399\n",
      "Bounding box: startX=183, startY=109, endX=265, endY=215\n",
      "Face shape: (106, 82, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9036112427711487\n",
      "Bounding box: startX=183, startY=111, endX=265, endY=218\n",
      "Face shape: (107, 82, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9134612679481506\n",
      "Bounding box: startX=184, startY=112, endX=265, endY=218\n",
      "Face shape: (106, 81, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9076056480407715\n",
      "Bounding box: startX=184, startY=114, endX=264, endY=217\n",
      "Face shape: (103, 80, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9254626035690308\n",
      "Bounding box: startX=185, startY=116, endX=265, endY=220\n",
      "Face shape: (104, 80, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9127562642097473\n",
      "Bounding box: startX=186, startY=118, endX=261, endY=218\n",
      "Face shape: (100, 75, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.928691565990448\n",
      "Bounding box: startX=185, startY=117, endX=261, endY=219\n",
      "Face shape: (102, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9248933792114258\n",
      "Bounding box: startX=186, startY=118, endX=262, endY=220\n",
      "Face shape: (102, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.9436020255088806\n",
      "Bounding box: startX=187, startY=117, endX=263, endY=220\n",
      "Face shape: (103, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9681482911109924\n",
      "Bounding box: startX=187, startY=118, endX=263, endY=220\n",
      "Face shape: (102, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9714818596839905\n",
      "Bounding box: startX=187, startY=117, endX=262, endY=222\n",
      "Face shape: (105, 75, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9504594802856445\n",
      "Bounding box: startX=186, startY=118, endX=263, endY=220\n",
      "Face shape: (102, 77, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9345906376838684\n",
      "Bounding box: startX=187, startY=118, endX=263, endY=222\n",
      "Face shape: (104, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9816122651100159\n",
      "Bounding box: startX=187, startY=118, endX=263, endY=221\n",
      "Face shape: (103, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9328957796096802\n",
      "Bounding box: startX=186, startY=117, endX=265, endY=223\n",
      "Face shape: (106, 79, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9635069966316223\n",
      "Bounding box: startX=188, startY=120, endX=263, endY=222\n",
      "Face shape: (102, 75, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9485028982162476\n",
      "Bounding box: startX=188, startY=120, endX=264, endY=224\n",
      "Face shape: (104, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9211829304695129\n",
      "Bounding box: startX=188, startY=121, endX=265, endY=226\n",
      "Face shape: (105, 77, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9342655539512634\n",
      "Bounding box: startX=188, startY=121, endX=264, endY=225\n",
      "Face shape: (104, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9337762594223022\n",
      "Bounding box: startX=187, startY=119, endX=265, endY=226\n",
      "Face shape: (107, 78, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9638045430183411\n",
      "Bounding box: startX=189, startY=122, endX=265, endY=226\n",
      "Face shape: (104, 76, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.8938304781913757\n",
      "Bounding box: startX=187, startY=120, endX=267, endY=228\n",
      "Face shape: (108, 80, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.8899257183074951\n",
      "Bounding box: startX=188, startY=120, endX=267, endY=229\n",
      "Face shape: (109, 79, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.966420590877533\n",
      "Bounding box: startX=189, startY=123, endX=264, endY=225\n",
      "Face shape: (102, 75, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Detection 0: confidence=0.8739802837371826\n",
      "Bounding box: startX=187, startY=121, endX=267, endY=225\n",
      "Face shape: (104, 80, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Detection 0: confidence=0.8777709603309631\n",
      "Bounding box: startX=190, startY=123, endX=264, endY=225\n",
      "Face shape: (102, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.946387767791748\n",
      "Bounding box: startX=191, startY=123, endX=262, endY=226\n",
      "Face shape: (103, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9610999226570129\n",
      "Bounding box: startX=192, startY=123, endX=264, endY=224\n",
      "Face shape: (101, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.939231812953949\n",
      "Bounding box: startX=192, startY=123, endX=264, endY=226\n",
      "Face shape: (103, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9370031952857971\n",
      "Bounding box: startX=193, startY=123, endX=265, endY=227\n",
      "Face shape: (104, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.8973796367645264\n",
      "Bounding box: startX=193, startY=124, endX=265, endY=228\n",
      "Face shape: (104, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.8579208254814148\n",
      "Bounding box: startX=193, startY=123, endX=265, endY=229\n",
      "Face shape: (106, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.902412474155426\n",
      "Bounding box: startX=193, startY=123, endX=265, endY=229\n",
      "Face shape: (106, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Detection 0: confidence=0.8911499381065369\n",
      "Bounding box: startX=193, startY=123, endX=266, endY=227\n",
      "Face shape: (104, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Detection 0: confidence=0.915765106678009\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=228\n",
      "Face shape: (105, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9183529615402222\n",
      "Bounding box: startX=193, startY=123, endX=263, endY=230\n",
      "Face shape: (107, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.902401328086853\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=229\n",
      "Face shape: (106, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.8736443519592285\n",
      "Bounding box: startX=193, startY=123, endX=266, endY=230\n",
      "Face shape: (107, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.943759024143219\n",
      "Bounding box: startX=193, startY=124, endX=264, endY=229\n",
      "Face shape: (105, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.8571956753730774\n",
      "Bounding box: startX=193, startY=123, endX=267, endY=228\n",
      "Face shape: (105, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9133601188659668\n",
      "Bounding box: startX=193, startY=122, endX=265, endY=231\n",
      "Face shape: (109, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.9285783767700195\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=230\n",
      "Face shape: (107, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.901313066482544\n",
      "Bounding box: startX=193, startY=124, endX=265, endY=229\n",
      "Face shape: (105, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Detection 0: confidence=0.9543615579605103\n",
      "Bounding box: startX=193, startY=125, endX=264, endY=231\n",
      "Face shape: (106, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Detection 0: confidence=0.898546576499939\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=232\n",
      "Face shape: (109, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9026004672050476\n",
      "Bounding box: startX=193, startY=123, endX=265, endY=229\n",
      "Face shape: (106, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9144095182418823\n",
      "Bounding box: startX=193, startY=123, endX=265, endY=231\n",
      "Face shape: (108, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.8695006370544434\n",
      "Bounding box: startX=192, startY=123, endX=265, endY=230\n",
      "Face shape: (107, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.8738666772842407\n",
      "Bounding box: startX=193, startY=123, endX=265, endY=230\n",
      "Face shape: (107, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Detection 0: confidence=0.9329906702041626\n",
      "Bounding box: startX=194, startY=123, endX=264, endY=229\n",
      "Face shape: (106, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.8955436944961548\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=230\n",
      "Face shape: (107, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9367163777351379\n",
      "Bounding box: startX=193, startY=123, endX=263, endY=230\n",
      "Face shape: (107, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Detection 0: confidence=0.9177951216697693\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=229\n",
      "Face shape: (106, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9144318103790283\n",
      "Bounding box: startX=193, startY=123, endX=264, endY=229\n",
      "Face shape: (106, 71, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9588354825973511\n",
      "Bounding box: startX=193, startY=124, endX=263, endY=229\n",
      "Face shape: (105, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9181535243988037\n",
      "Bounding box: startX=193, startY=124, endX=263, endY=229\n",
      "Face shape: (105, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9254074096679688\n",
      "Bounding box: startX=193, startY=123, endX=263, endY=230\n",
      "Face shape: (107, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9080867767333984\n",
      "Bounding box: startX=193, startY=124, endX=263, endY=230\n",
      "Face shape: (106, 70, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Detection 0: confidence=0.9361456036567688\n",
      "Bounding box: startX=193, startY=123, endX=266, endY=229\n",
      "Face shape: (106, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.8864424824714661\n",
      "Bounding box: startX=193, startY=123, endX=266, endY=230\n",
      "Face shape: (107, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9296676516532898\n",
      "Bounding box: startX=193, startY=124, endX=264, endY=228\n",
      "Face shape: (104, 71, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9636863470077515\n",
      "Bounding box: startX=193, startY=124, endX=262, endY=226\n",
      "Face shape: (102, 69, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9904088973999023\n",
      "Bounding box: startX=191, startY=124, endX=263, endY=225\n",
      "Face shape: (101, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9879823923110962\n",
      "Bounding box: startX=191, startY=124, endX=264, endY=225\n",
      "Face shape: (101, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9843063354492188\n",
      "Bounding box: startX=192, startY=126, endX=265, endY=225\n",
      "Face shape: (99, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9819837808609009\n",
      "Bounding box: startX=192, startY=124, endX=265, endY=225\n",
      "Face shape: (101, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Detection 0: confidence=0.9906865954399109\n",
      "Bounding box: startX=192, startY=125, endX=264, endY=225\n",
      "Face shape: (100, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9919877052307129\n",
      "Bounding box: startX=192, startY=126, endX=264, endY=223\n",
      "Face shape: (97, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Detection 0: confidence=0.9899042248725891\n",
      "Bounding box: startX=192, startY=124, endX=264, endY=222\n",
      "Face shape: (98, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Detection 0: confidence=0.9872965812683105\n",
      "Bounding box: startX=192, startY=123, endX=265, endY=223\n",
      "Face shape: (100, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9932700991630554\n",
      "Bounding box: startX=192, startY=122, endX=264, endY=223\n",
      "Face shape: (101, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9929071664810181\n",
      "Bounding box: startX=192, startY=122, endX=264, endY=223\n",
      "Face shape: (101, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Detection 0: confidence=0.9965680837631226\n",
      "Bounding box: startX=192, startY=122, endX=264, endY=222\n",
      "Face shape: (100, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.9963977336883545\n",
      "Bounding box: startX=191, startY=121, endX=264, endY=222\n",
      "Face shape: (101, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9961199760437012\n",
      "Bounding box: startX=190, startY=119, endX=264, endY=221\n",
      "Face shape: (102, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9916183352470398\n",
      "Bounding box: startX=191, startY=122, endX=264, endY=224\n",
      "Face shape: (102, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9972659349441528\n",
      "Bounding box: startX=190, startY=119, endX=264, endY=221\n",
      "Face shape: (102, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9979212880134583\n",
      "Bounding box: startX=191, startY=120, endX=263, endY=221\n",
      "Face shape: (101, 72, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9982452392578125\n",
      "Bounding box: startX=189, startY=119, endX=263, endY=220\n",
      "Face shape: (101, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.9982287287712097\n",
      "Bounding box: startX=190, startY=118, endX=263, endY=221\n",
      "Face shape: (103, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9982238411903381\n",
      "Bounding box: startX=190, startY=119, endX=263, endY=221\n",
      "Face shape: (102, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Detection 0: confidence=0.998019814491272\n",
      "Bounding box: startX=190, startY=119, endX=263, endY=221\n",
      "Face shape: (102, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Detection 0: confidence=0.9983457326889038\n",
      "Bounding box: startX=190, startY=119, endX=263, endY=220\n",
      "Face shape: (101, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9976674914360046\n",
      "Bounding box: startX=190, startY=119, endX=263, endY=221\n",
      "Face shape: (102, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9970362186431885\n",
      "Bounding box: startX=189, startY=119, endX=263, endY=221\n",
      "Face shape: (102, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.998796820640564\n",
      "Bounding box: startX=189, startY=119, endX=263, endY=221\n",
      "Face shape: (102, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9980779886245728\n",
      "Bounding box: startX=189, startY=119, endX=263, endY=220\n",
      "Face shape: (101, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.998096764087677\n",
      "Bounding box: startX=189, startY=120, endX=263, endY=221\n",
      "Face shape: (101, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9985900521278381\n",
      "Bounding box: startX=189, startY=119, endX=263, endY=221\n",
      "Face shape: (102, 74, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.9979721903800964\n",
      "Bounding box: startX=189, startY=119, endX=262, endY=221\n",
      "Face shape: (102, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.997732400894165\n",
      "Bounding box: startX=189, startY=119, endX=262, endY=221\n",
      "Face shape: (102, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9983847141265869\n",
      "Bounding box: startX=189, startY=119, endX=262, endY=219\n",
      "Face shape: (100, 73, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebcamVideoStream' object has no attribute 'release'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# do a bit of cleanup\u001b[39;00m\n\u001b[0;32m     48\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 50\u001b[0m vs\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebcamVideoStream' object has no attribute 'release'"
     ]
    }
   ],
   "source": [
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # detect faces in the frame and determine if they are wearing a\n",
    "    # face mask or not\n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "    # loop over the detected face locations and their corresponding\n",
    "    # locations\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        # unpack the bounding box and predictions\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        # determine the class label and color we'll use to draw\n",
    "        # the bounding box and text\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "        # include the probability in the label\n",
    "        #label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "        \n",
    "        # display the label and bounding box rectangle on the output\n",
    "        # frame\n",
    "        if(label==\"Mask\"):    \n",
    "            cv2.putText(frame,\"Mask: You are allowed\", (startX, startY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "        elif(label==\"No Mask\"):\n",
    "            lab=\"No Mask: You are not allowed\"\n",
    "            cv2.putText(frame, lab, (startX, startY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
